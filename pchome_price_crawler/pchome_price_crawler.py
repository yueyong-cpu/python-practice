# pchome_price_crawler.py
import requests
import urllib.parse
import pandas as pd

def crawl_pchome(keyword, max_results=20):
    encoded_keyword = urllib.parse.quote(keyword)
    url = f"https://ecshweb.pchome.com.tw/search/v3.3/all/results?q={encoded_keyword}&page=1&sort=rnk/dc"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    }

    res = requests.get(url, headers=headers)
    if res.status_code != 200:
        print("âŒ ç„¡æ³•é€£ç·šåˆ° PChome")
        return pd.DataFrame()

    data = res.json()
    if 'prods' not in data:
        print("â— æ‰¾ä¸åˆ°å•†å“è³‡æ–™ï¼Œå¯èƒ½é—œéµå­—å¤ªæ¨¡ç³Šæˆ–è¢«æ“‹çˆ¬")
        return pd.DataFrame()

    titles = []
    prices = []
    urls = []

    for item in data['prods'][:max_results]:
        titles.append(item['name'])
        prices.append(item['price'])
        urls.append(f"https://24h.pchome.com.tw/prod/{item['Id']}")

    df = pd.DataFrame({
        "å•†å“åç¨±": titles,
        "åƒ¹æ ¼": prices,
        "é€£çµ": urls
    })
    return df

if __name__ == "__main__":
    keyword = input("è«‹è¼¸å…¥æœå°‹å•†å“é—œéµå­—ï¼ˆä¾‹å¦‚ ç¾…æŠ€ éµç›¤ï¼‰ï¼š")
    result = crawl_pchome(keyword)
    if not result.empty:
        print("\nğŸ” æœå°‹çµæœï¼š")
        print(result)
        result.to_excel(f"{keyword}_pchomeæ¯”åƒ¹.xlsx", index=False)
        print(f"\nâœ… å·²è¼¸å‡ºå ±è¡¨ï¼š{keyword}_pchomeæ¯”åƒ¹.xlsx")
