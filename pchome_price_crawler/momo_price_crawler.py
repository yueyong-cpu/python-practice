# momo_price_crawler.py
import requests
from bs4 import BeautifulSoup
import pandas as pd

def crawl_momo(keyword, max_results=10):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    }

    url = f"https://www.momoshop.com.tw/search/searchShop.jsp?keyword={keyword}"
    res = requests.get(url, headers=headers)
    res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')

    titles = [tag.text.strip() for tag in soup.select('.prdName')][:max_results]
    prices = [tag.text.strip().replace(',', '') for tag in soup.select('.price')][:max_results]
    links = ["https://www.momoshop.com.tw" + tag['href'] for tag in soup.select('.prdName > a')][:max_results]

    data = pd.DataFrame({
        'å•†å“åç¨±': titles,
        'åƒ¹æ ¼': prices,
        'é€£çµ': links
    })
    return data

if __name__ == "__main__":
    keyword = input("è«‹è¼¸å…¥æœå°‹å•†å“é—œéµå­—ï¼š")
    result = crawl_momo(keyword)
    print("\nğŸ” æœå°‹çµæœï¼š")
    print(result)
    result.to_excel(f"{keyword}_æ¯”åƒ¹çµæœ.xlsx", index=False)
    print(f"\nâœ… å·²è¼¸å‡ºå ±è¡¨ï¼š{keyword}_æ¯”åƒ¹çµæœ.xlsx")
